# Day 13 â€” OOP ETL Pipeline (Class-Based Data Job)

## ğŸ“Œ Objective
Build a class-based ETL (Extractâ€“Transformâ€“Load) pipeline using Python and Pandas.  
Instead of writing loose scripts, this project structures the data workflow using Object-Oriented Programming (OOP), similar to how production data pipelines are designed.

---

## ğŸ§  Concepts Covered

- Python Classes & OOP
- __init__ constructor
- Instance variables
- Method-based pipeline stages
- ETL design pattern
- Pandas aggregation
- CSV ingestion and export
- Modular pipeline structure

---

## âš™ï¸ ETL Stages Implemented

### 1ï¸âƒ£ Extract
- Read CSV file using Pandas
- Load into DataFrame

### 2ï¸âƒ£ Transform
- Convert marks column to numeric
- Handle invalid values
- Group by student name
- Compute average marks

### 3ï¸âƒ£ Load
- Save transformed output to CSV

### 4ï¸âƒ£ Run
- Orchestrates extract â†’ transform â†’ load sequence

---

## ğŸ“‚ Project Structure

Day13_OOP_ETL/
â”‚
â”œâ”€â”€ etl_pipeline.py
â”œâ”€â”€ input.csv
â”œâ”€â”€ output.csv
â””â”€â”€ README.md

---

## ğŸ“„ Sample Input (input.csv)

name,marks
Riya,88
Aryan,75
Sneha,92
Riya,90
Aryan,85

---

## â–¶ï¸ How to Run

Install dependency:

    pip install pandas

Run pipeline:

    python etl_pipeline.py

---

## ğŸ“Š Sample Output (output.csv)

name,avg_marks
Aryan,80.0
Riya,89.0
Sneha,92.0

---

## ğŸ—ï¸ Why OOP for Data Pipelines?

Using classes makes pipelines:

- Reusable
- Configurable
- Testable
- Modular
- Production-friendly

Each ETL stage is a method:
- extract()
- transform()
- load()b 
- run()

This mirrors real-world pipeline frameworks like Airflow operators and ETL job classes.

---

## ğŸ’¬ Interview Explanation (Short Version)

This project demonstrates a class-based ETL pipeline where extract, transform, and load are implemented as methods. The pipeline is configurable via constructor parameters and executed through a run() orchestrator method, following production ETL design patterns.

---

## ğŸš€ Next Step

Day 14 â†’ Logging + Configurable Pipelines  
(Add logging, config files, and environment separation to make this production-grade.)
